{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "069f78c1",
   "metadata": {},
   "source": [
    "### RAG pipelines - Data Imgestion to vector DB pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57ce483e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.document_loaders import PyPDFLoader, PyMuPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1ec14e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../data/pdf\n",
      "[PosixPath('../data/pdf/objectdetection.pdf'), PosixPath('../data/pdf/embeddings.pdf'), PosixPath('../data/pdf/attention.pdf'), PosixPath('../data/pdf/proposal.pdf')]\n",
      "\n",
      " Processing objectdetection.pdf\n",
      "\n",
      " Processed objectdetection.pdf\n",
      "\n",
      " Processing embeddings.pdf\n",
      "\n",
      " Processed embeddings.pdf\n",
      "\n",
      " Processing attention.pdf\n",
      "\n",
      " Processed attention.pdf\n",
      "\n",
      " Processing proposal.pdf\n",
      "\n",
      " Processed proposal.pdf\n",
      "Processed total 4\n"
     ]
    }
   ],
   "source": [
    "def process_all_pdfs(pdf_directory):\n",
    "    \"\"\"Process all the pdf files\"\"\"\n",
    "    all_documents =[]\n",
    "    pdf_dir = Path(pdf_directory)\n",
    "    print(pdf_dir)\n",
    "    \n",
    "    #Find all the pdf files\n",
    "    pdf_files = list(pdf_dir.glob(\"**/*.pdf\"))\n",
    "    print(pdf_files)\n",
    "    \n",
    "    for pdf_file in pdf_files:\n",
    "        print(f\"\\n Processing {pdf_file.name}\")\n",
    "        try:\n",
    "            loader = PyMuPDFLoader(str(pdf_file))\n",
    "            documents = loader.load()\n",
    "            \n",
    "            # Add source information to metadata\n",
    "            for doc in documents:\n",
    "                doc.metadata['source_file']= pdf_file.name\n",
    "                doc.metadata['file_type'] = 'pdf'\n",
    "                \n",
    "            all_documents.extend(documents)\n",
    "            print(f\"\\n Processed {pdf_file.name}\")   \n",
    "        except Exception as e:\n",
    "            print(f\" Error occured while processing {pdf_file.name}, {e}\")\n",
    "            \n",
    "    print(f\"Processed total {len(pdf_files)}\")\n",
    "    return all_documents\n",
    "                \n",
    "    \n",
    "all_pdf_documents = process_all_pdfs(\"../data/pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "661a82c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Title: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults: \\n \\nYOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy. \\n \\nTitle: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults:'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='YOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Title: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults: \\n \\nYOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Title: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults: \\n \\nYOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Title: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults: \\n \\nYOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Title: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults: \\n \\nYOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Title: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults: \\n \\nYOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Title: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults: \\n \\nYOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 8, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Title: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults: \\n \\nYOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 9, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Title: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults: \\n \\nYOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 10, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Title: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults: \\n \\nYOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 11, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Title: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults: \\n \\nYOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 12, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Title: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults: \\n \\nYOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 13, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Title: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults: \\n \\nYOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 14, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}, page_content='Title: A Comparative Study of CNN-Based Object Detection Models \\n \\nAbstract: \\nThis research analyzes single-stage and two-stage object detection models using a benchmark \\nimage dataset. \\n \\nIntroduction: \\nObject detection identifies and localizes objects within images using bounding boxes. \\n \\nMethodology: \\n \\nEvaluated Faster R-CNN (two-stage model). \\n \\nEvaluated YOLO (single-stage model). \\n \\nCompared inference speed and detection accuracy. \\n \\nResults: \\n \\nYOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Title: Comparative Analysis of Word Embedding Techniques \\n \\nAbstract: \\nThis paper compares Word2Vec, GloVe, and contextual embeddings for semantic similarity \\ntasks. The goal is to evaluate embedding quality using cosine similarity metrics. \\n \\nIntroduction: \\nWord embeddings map words into dense vector space representations, preserving semantic \\nrelationships. \\n \\nMethodology: \\n \\nTrained Word2Vec on a small corpus. \\n \\nEvaluated similarity scores between related word pairs. \\n \\nCompared with pre-trained contextual embeddings. \\n \\nResults: \\n \\nContextual embeddings captured polysemy better. \\n \\nStatic embeddings performed efficiently on smaller datasets. \\n \\nConclusion: \\nContextual embeddings outperform static embeddings in semantic understanding tasks. \\n \\nTitle: Comparative Analysis of Word Embedding Techniques \\n \\nAbstract: \\nThis paper compares Word2Vec, GloVe, and contextual embeddings for semantic similarity \\ntasks. The goal is to evaluate embedding quality using cosine similarity metrics. \\n \\nIntroduction: \\nWord embeddings map words into dense vector space representations, preserving semantic \\nrelationships. \\n \\nMethodology: \\n \\nTrained Word2Vec on a small corpus. \\n \\nEvaluated similarity scores between related word pairs. \\n \\nCompared with pre-trained contextual embeddings.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Results: \\n \\nContextual embeddings captured polysemy better. \\n \\nStatic embeddings performed efficiently on smaller datasets. \\n \\nConclusion: \\nContextual embeddings outperform static embeddings in semantic understanding tasks.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Title: Comparative Analysis of Word Embedding Techniques \\n \\nAbstract: \\nThis paper compares Word2Vec, GloVe, and contextual embeddings for semantic similarity \\ntasks. The goal is to evaluate embedding quality using cosine similarity metrics. \\n \\nIntroduction: \\nWord embeddings map words into dense vector space representations, preserving semantic \\nrelationships. \\n \\nMethodology: \\n \\nTrained Word2Vec on a small corpus. \\n \\nEvaluated similarity scores between related word pairs. \\n \\nCompared with pre-trained contextual embeddings. \\n \\nResults: \\n \\nContextual embeddings captured polysemy better. \\n \\nStatic embeddings performed efficiently on smaller datasets. \\n \\nConclusion: \\nContextual embeddings outperform static embeddings in semantic understanding tasks.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Title: Comparative Analysis of Word Embedding Techniques \\n \\nAbstract: \\nThis paper compares Word2Vec, GloVe, and contextual embeddings for semantic similarity \\ntasks. The goal is to evaluate embedding quality using cosine similarity metrics. \\n \\nIntroduction: \\nWord embeddings map words into dense vector space representations, preserving semantic \\nrelationships. \\n \\nMethodology: \\n \\nTrained Word2Vec on a small corpus. \\n \\nEvaluated similarity scores between related word pairs. \\n \\nCompared with pre-trained contextual embeddings. \\n \\nResults: \\n \\nContextual embeddings captured polysemy better. \\n \\nStatic embeddings performed efficiently on smaller datasets. \\n \\nConclusion: \\nContextual embeddings outperform static embeddings in semantic understanding tasks.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Title: Comparative Analysis of Word Embedding Techniques \\n \\nAbstract: \\nThis paper compares Word2Vec, GloVe, and contextual embeddings for semantic similarity \\ntasks. The goal is to evaluate embedding quality using cosine similarity metrics. \\n \\nIntroduction: \\nWord embeddings map words into dense vector space representations, preserving semantic \\nrelationships. \\n \\nMethodology: \\n \\nTrained Word2Vec on a small corpus. \\n \\nEvaluated similarity scores between related word pairs. \\n \\nCompared with pre-trained contextual embeddings. \\n \\nResults: \\n \\nContextual embeddings captured polysemy better. \\n \\nStatic embeddings performed efficiently on smaller datasets. \\n \\nConclusion: \\nContextual embeddings outperform static embeddings in semantic understanding tasks.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Title: Comparative Analysis of Word Embedding Techniques \\n \\nAbstract: \\nThis paper compares Word2Vec, GloVe, and contextual embeddings for semantic similarity \\ntasks. The goal is to evaluate embedding quality using cosine similarity metrics. \\n \\nIntroduction: \\nWord embeddings map words into dense vector space representations, preserving semantic \\nrelationships. \\n \\nMethodology: \\n \\nTrained Word2Vec on a small corpus. \\n \\nEvaluated similarity scores between related word pairs. \\n \\nCompared with pre-trained contextual embeddings. \\n \\nResults: \\n \\nContextual embeddings captured polysemy better. \\n \\nStatic embeddings performed efficiently on smaller datasets. \\n \\nConclusion: \\nContextual embeddings outperform static embeddings in semantic understanding tasks.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Title: Comparative Analysis of Word Embedding Techniques \\n \\nAbstract: \\nThis paper compares Word2Vec, GloVe, and contextual embeddings for semantic similarity \\ntasks. The goal is to evaluate embedding quality using cosine similarity metrics. \\n \\nIntroduction: \\nWord embeddings map words into dense vector space representations, preserving semantic \\nrelationships. \\n \\nMethodology: \\n \\nTrained Word2Vec on a small corpus. \\n \\nEvaluated similarity scores between related word pairs. \\n \\nCompared with pre-trained contextual embeddings. \\n \\nResults: \\n \\nContextual embeddings captured polysemy better. \\n \\nStatic embeddings performed efficiently on smaller datasets. \\n \\nConclusion: \\nContextual embeddings outperform static embeddings in semantic understanding tasks.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Title: Comparative Analysis of Word Embedding Techniques \\n \\nAbstract: \\nThis paper compares Word2Vec, GloVe, and contextual embeddings for semantic similarity \\ntasks. The goal is to evaluate embedding quality using cosine similarity metrics. \\n \\nIntroduction: \\nWord embeddings map words into dense vector space representations, preserving semantic \\nrelationships. \\n \\nMethodology: \\n \\nTrained Word2Vec on a small corpus. \\n \\nEvaluated similarity scores between related word pairs. \\n \\nCompared with pre-trained contextual embeddings. \\n \\nResults: \\n \\nContextual embeddings captured polysemy better. \\n \\nStatic embeddings performed efficiently on smaller datasets. \\n \\nConclusion: \\nContextual embeddings outperform static embeddings in semantic understanding tasks. \\n \\nTitle: Comparative Analysis of Word Embedding Techniques \\n \\nAbstract: \\nThis paper compares Word2Vec, GloVe, and contextual embeddings for semantic similarity \\ntasks. The goal is to evaluate embedding quality using cosine similarity metrics. \\n \\nIntroduction: \\nWord embeddings map words into dense vector space representations, preserving semantic \\nrelationships. \\n \\nMethodology: \\n \\nTrained Word2Vec on a small corpus. \\n \\nEvaluated similarity scores between related word pairs. \\n \\nCompared with pre-trained contextual embeddings.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 8, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Results: \\n \\nContextual embeddings captured polysemy better. \\n \\nStatic embeddings performed efficiently on smaller datasets. \\n \\nConclusion: \\nContextual embeddings outperform static embeddings in semantic understanding tasks.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 9, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Title: Comparative Analysis of Word Embedding Techniques \\n \\nAbstract: \\nThis paper compares Word2Vec, GloVe, and contextual embeddings for semantic similarity \\ntasks. The goal is to evaluate embedding quality using cosine similarity metrics. \\n \\nIntroduction: \\nWord embeddings map words into dense vector space representations, preserving semantic \\nrelationships. \\n \\nMethodology: \\n \\nTrained Word2Vec on a small corpus. \\n \\nEvaluated similarity scores between related word pairs. \\n \\nCompared with pre-trained contextual embeddings. \\n \\nResults: \\n \\nContextual embeddings captured polysemy better. \\n \\nStatic embeddings performed efficiently on smaller datasets. \\n \\nConclusion: \\nContextual embeddings outperform static embeddings in semantic understanding tasks.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 10, 'source_file': 'embeddings.pdf', 'file_type': 'pdf'}, page_content='Title: Comparative Analysis of Word Embedding Techniques \\n \\nAbstract: \\nThis paper compares Word2Vec, GloVe, and contextual embeddings for semantic similarity \\ntasks. The goal is to evaluate embedding quality using cosine similarity metrics. \\n \\nIntroduction: \\nWord embeddings map words into dense vector space representations, preserving semantic \\nrelationships. \\n \\nMethodology: \\n \\nTrained Word2Vec on a small corpus. \\n \\nEvaluated similarity scores between related word pairs. \\n \\nCompared with pre-trained contextual embeddings. \\n \\nResults: \\n \\nContextual embeddings captured polysemy better. \\n \\nStatic embeddings performed efficiently on smaller datasets. \\n \\nConclusion: \\nContextual embeddings outperform static embeddings in semantic understanding tasks.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Title: A Lightweight Study on Attention Mechanisms in Neural Networks \\n \\nAbstract: \\nAttention mechanisms allow neural networks to dynamically focus on relevant parts of input \\ndata. This study evaluates scaled dot-product attention in sequence modeling tasks and \\nanalyzes its computational efficiency and contextual learning capabilities. \\n \\nIntroduction: \\nTraditional recurrent models struggle with long-range dependencies. Attention improves \\nrepresentation learning by assigning weights to important tokens in the input sequence. \\n \\nMethodology: \\n \\nImplemented scaled dot-product attention. \\n \\nCompared attention-based model with baseline LSTM. \\n \\nEvaluated on a small text classification dataset. \\n \\nResults: \\n \\nImproved contextual understanding. \\n \\nReduced dependency loss in longer sequences. \\n \\nFaster convergence compared to vanilla LSTM. \\n \\nConclusion: \\nAttention significantly enhances sequence modeling and forms the foundation of transformer \\narchitectures. \\n \\nTitle: A Lightweight Study on Attention Mechanisms in Neural Networks \\n \\nAbstract: \\nAttention mechanisms allow neural networks to dynamically focus on relevant parts of input \\ndata. This study evaluates scaled dot-product attention in sequence modeling tasks and \\nanalyzes its computational efficiency and contextual learning capabilities. \\n \\nIntroduction: \\nTraditional recurrent models struggle with long-range dependencies. Attention improves \\nrepresentation learning by assigning weights to important tokens in the input sequence. \\n \\nMethodology:'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Implemented scaled dot-product attention. \\n \\nCompared attention-based model with baseline LSTM. \\n \\nEvaluated on a small text classification dataset. \\n \\nResults: \\n \\nImproved contextual understanding. \\n \\nReduced dependency loss in longer sequences. \\n \\nFaster convergence compared to vanilla LSTM. \\n \\nConclusion: \\nAttention significantly enhances sequence modeling and forms the foundation of transformer \\narchitectures.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Title: A Lightweight Study on Attention Mechanisms in Neural Networks \\n \\nAbstract: \\nAttention mechanisms allow neural networks to dynamically focus on relevant parts of input \\ndata. This study evaluates scaled dot-product attention in sequence modeling tasks and \\nanalyzes its computational efficiency and contextual learning capabilities. \\n \\nIntroduction: \\nTraditional recurrent models struggle with long-range dependencies. Attention improves \\nrepresentation learning by assigning weights to important tokens in the input sequence. \\n \\nMethodology: \\n \\nImplemented scaled dot-product attention. \\n \\nCompared attention-based model with baseline LSTM. \\n \\nEvaluated on a small text classification dataset. \\n \\nResults: \\n \\nImproved contextual understanding. \\n \\nReduced dependency loss in longer sequences. \\n \\nFaster convergence compared to vanilla LSTM. \\n \\nConclusion: \\nAttention significantly enhances sequence modeling and forms the foundation of transformer \\narchitectures.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Title: A Lightweight Study on Attention Mechanisms in Neural Networks \\n \\nAbstract: \\nAttention mechanisms allow neural networks to dynamically focus on relevant parts of input \\ndata. This study evaluates scaled dot-product attention in sequence modeling tasks and \\nanalyzes its computational efficiency and contextual learning capabilities. \\n \\nIntroduction: \\nTraditional recurrent models struggle with long-range dependencies. Attention improves \\nrepresentation learning by assigning weights to important tokens in the input sequence. \\n \\nMethodology: \\n \\nImplemented scaled dot-product attention. \\n \\nCompared attention-based model with baseline LSTM. \\n \\nEvaluated on a small text classification dataset. \\n \\nResults: \\n \\nImproved contextual understanding. \\n \\nReduced dependency loss in longer sequences. \\n \\nFaster convergence compared to vanilla LSTM. \\n \\nConclusion: \\nAttention significantly enhances sequence modeling and forms the foundation of transformer \\narchitectures.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Title: A Lightweight Study on Attention Mechanisms in Neural Networks \\n \\nAbstract: \\nAttention mechanisms allow neural networks to dynamically focus on relevant parts of input \\ndata. This study evaluates scaled dot-product attention in sequence modeling tasks and \\nanalyzes its computational efficiency and contextual learning capabilities. \\n \\nIntroduction: \\nTraditional recurrent models struggle with long-range dependencies. Attention improves \\nrepresentation learning by assigning weights to important tokens in the input sequence. \\n \\nMethodology: \\n \\nImplemented scaled dot-product attention. \\n \\nCompared attention-based model with baseline LSTM. \\n \\nEvaluated on a small text classification dataset. \\n \\nResults: \\n \\nImproved contextual understanding. \\n \\nReduced dependency loss in longer sequences. \\n \\nFaster convergence compared to vanilla LSTM. \\n \\nConclusion: \\nAttention significantly enhances sequence modeling and forms the foundation of transformer \\narchitectures.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Title: A Lightweight Study on Attention Mechanisms in Neural Networks \\n \\nAbstract: \\nAttention mechanisms allow neural networks to dynamically focus on relevant parts of input \\ndata. This study evaluates scaled dot-product attention in sequence modeling tasks and \\nanalyzes its computational efficiency and contextual learning capabilities. \\n \\nIntroduction: \\nTraditional recurrent models struggle with long-range dependencies. Attention improves \\nrepresentation learning by assigning weights to important tokens in the input sequence. \\n \\nMethodology: \\n \\nImplemented scaled dot-product attention. \\n \\nCompared attention-based model with baseline LSTM. \\n \\nEvaluated on a small text classification dataset. \\n \\nResults: \\n \\nImproved contextual understanding. \\n \\nReduced dependency loss in longer sequences. \\n \\nFaster convergence compared to vanilla LSTM. \\n \\nConclusion: \\nAttention significantly enhances sequence modeling and forms the foundation of transformer \\narchitectures.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Title: A Lightweight Study on Attention Mechanisms in Neural Networks \\n \\nAbstract: \\nAttention mechanisms allow neural networks to dynamically focus on relevant parts of input \\ndata. This study evaluates scaled dot-product attention in sequence modeling tasks and \\nanalyzes its computational efficiency and contextual learning capabilities. \\n \\nIntroduction: \\nTraditional recurrent models struggle with long-range dependencies. Attention improves \\nrepresentation learning by assigning weights to important tokens in the input sequence. \\n \\nMethodology: \\n \\nImplemented scaled dot-product attention. \\n \\nCompared attention-based model with baseline LSTM. \\n \\nEvaluated on a small text classification dataset. \\n \\nResults: \\n \\nImproved contextual understanding. \\n \\nReduced dependency loss in longer sequences. \\n \\nFaster convergence compared to vanilla LSTM. \\n \\nConclusion: \\nAttention significantly enhances sequence modeling and forms the foundation of transformer \\narchitectures.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Title: A Lightweight Study on Attention Mechanisms in Neural Networks \\n \\nAbstract: \\nAttention mechanisms allow neural networks to dynamically focus on relevant parts of input \\ndata. This study evaluates scaled dot-product attention in sequence modeling tasks and \\nanalyzes its computational efficiency and contextual learning capabilities. \\n \\nIntroduction: \\nTraditional recurrent models struggle with long-range dependencies. Attention improves \\nrepresentation learning by assigning weights to important tokens in the input sequence. \\n \\nMethodology: \\n \\nImplemented scaled dot-product attention. \\n \\nCompared attention-based model with baseline LSTM. \\n \\nEvaluated on a small text classification dataset. \\n \\nResults: \\n \\nImproved contextual understanding. \\n \\nReduced dependency loss in longer sequences. \\n \\nFaster convergence compared to vanilla LSTM. \\n \\nConclusion: \\nAttention significantly enhances sequence modeling and forms the foundation of transformer \\narchitectures.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 8, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Title: A Lightweight Study on Attention Mechanisms in Neural Networks \\n \\nAbstract: \\nAttention mechanisms allow neural networks to dynamically focus on relevant parts of input \\ndata. This study evaluates scaled dot-product attention in sequence modeling tasks and \\nanalyzes its computational efficiency and contextual learning capabilities. \\n \\nIntroduction: \\nTraditional recurrent models struggle with long-range dependencies. Attention improves \\nrepresentation learning by assigning weights to important tokens in the input sequence. \\n \\nMethodology: \\n \\nImplemented scaled dot-product attention. \\n \\nCompared attention-based model with baseline LSTM. \\n \\nEvaluated on a small text classification dataset. \\n \\nResults: \\n \\nImproved contextual understanding. \\n \\nReduced dependency loss in longer sequences. \\n \\nFaster convergence compared to vanilla LSTM. \\n \\nConclusion: \\nAttention significantly enhances sequence modeling and forms the foundation of transformer \\narchitectures.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 9, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Title: A Lightweight Study on Attention Mechanisms in Neural Networks \\n \\nAbstract: \\nAttention mechanisms allow neural networks to dynamically focus on relevant parts of input \\ndata. This study evaluates scaled dot-product attention in sequence modeling tasks and \\nanalyzes its computational efficiency and contextual learning capabilities. \\n \\nIntroduction: \\nTraditional recurrent models struggle with long-range dependencies. Attention improves \\nrepresentation learning by assigning weights to important tokens in the input sequence. \\n \\nMethodology: \\n \\nImplemented scaled dot-product attention. \\n \\nCompared attention-based model with baseline LSTM. \\n \\nEvaluated on a small text classification dataset. \\n \\nResults: \\n \\nImproved contextual understanding. \\n \\nReduced dependency loss in longer sequences. \\n \\nFaster convergence compared to vanilla LSTM. \\n \\nConclusion: \\nAttention significantly enhances sequence modeling and forms the foundation of transformer \\narchitectures.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 10, 'source_file': 'attention.pdf', 'file_type': 'pdf'}, page_content='Title: A Lightweight Study on Attention Mechanisms in Neural Networks \\n \\nAbstract: \\nAttention mechanisms allow neural networks to dynamically focus on relevant parts of input \\ndata. This study evaluates scaled dot-product attention in sequence modeling tasks and \\nanalyzes its computational efficiency and contextual learning capabilities. \\n \\nIntroduction: \\nTraditional recurrent models struggle with long-range dependencies. Attention improves \\nrepresentation learning by assigning weights to important tokens in the input sequence. \\n \\nMethodology: \\n \\nImplemented scaled dot-product attention. \\n \\nCompared attention-based model with baseline LSTM. \\n \\nEvaluated on a small text classification dataset. \\n \\nResults: \\n \\nImproved contextual understanding. \\n \\nReduced dependency loss in longer sequences. \\n \\nFaster convergence compared to vanilla LSTM. \\n \\nConclusion: \\nAttention significantly enhances sequence modeling and forms the foundation of transformer \\narchitectures.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'proposal.pdf', 'file_type': 'pdf'}, page_content='Title: Proposal for a Multi-Modal Transformer Model \\n \\nProblem Statement: \\nCurrent models struggle to efficiently combine text and image features for contextual \\nunderstanding. \\n \\nObjective: \\nDevelop a lightweight transformer model integrating visual and textual embeddings. \\n \\nProposed Method: \\n \\nUse pre-trained visual encoder for image features. \\n \\nUse transformer-based text encoder. \\n \\nFuse embeddings using cross-attention layers. \\n \\nExpected Outcomes: \\n \\nImproved contextual understanding across modalities. \\n \\nEfficient representation learning for multi-modal tasks. \\n \\nFuture Work: \\n \\nExtend to video-text tasks. \\n \\nOptimize for real-time deployment. \\n \\nTitle: Proposal for a Multi-Modal Transformer Model \\n \\nProblem Statement: \\nCurrent models struggle to efficiently combine text and image features for contextual \\nunderstanding. \\n \\nObjective: \\nDevelop a lightweight transformer model integrating visual and textual embeddings. \\n \\nProposed Method: \\n \\nUse pre-trained visual encoder for image features. \\n \\nUse transformer-based text encoder.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1, 'source_file': 'proposal.pdf', 'file_type': 'pdf'}, page_content='Fuse embeddings using cross-attention layers. \\n \\nExpected Outcomes: \\n \\nImproved contextual understanding across modalities. \\n \\nEfficient representation learning for multi-modal tasks. \\n \\nFuture Work: \\n \\nExtend to video-text tasks. \\n \\nOptimize for real-time deployment.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2, 'source_file': 'proposal.pdf', 'file_type': 'pdf'}, page_content='Title: Proposal for a Multi-Modal Transformer Model \\n \\nProblem Statement: \\nCurrent models struggle to efficiently combine text and image features for contextual \\nunderstanding. \\n \\nObjective: \\nDevelop a lightweight transformer model integrating visual and textual embeddings. \\n \\nProposed Method: \\n \\nUse pre-trained visual encoder for image features. \\n \\nUse transformer-based text encoder. \\n \\nFuse embeddings using cross-attention layers. \\n \\nExpected Outcomes: \\n \\nImproved contextual understanding across modalities. \\n \\nEfficient representation learning for multi-modal tasks. \\n \\nFuture Work: \\n \\nExtend to video-text tasks. \\n \\nOptimize for real-time deployment.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3, 'source_file': 'proposal.pdf', 'file_type': 'pdf'}, page_content='Title: Proposal for a Multi-Modal Transformer Model \\n \\nProblem Statement: \\nCurrent models struggle to efficiently combine text and image features for contextual \\nunderstanding. \\n \\nObjective: \\nDevelop a lightweight transformer model integrating visual and textual embeddings. \\n \\nProposed Method: \\n \\nUse pre-trained visual encoder for image features. \\n \\nUse transformer-based text encoder. \\n \\nFuse embeddings using cross-attention layers. \\n \\nExpected Outcomes: \\n \\nImproved contextual understanding across modalities. \\n \\nEfficient representation learning for multi-modal tasks. \\n \\nFuture Work: \\n \\nExtend to video-text tasks. \\n \\nOptimize for real-time deployment.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4, 'source_file': 'proposal.pdf', 'file_type': 'pdf'}, page_content='Title: Proposal for a Multi-Modal Transformer Model \\n \\nProblem Statement: \\nCurrent models struggle to efficiently combine text and image features for contextual \\nunderstanding. \\n \\nObjective: \\nDevelop a lightweight transformer model integrating visual and textual embeddings. \\n \\nProposed Method: \\n \\nUse pre-trained visual encoder for image features. \\n \\nUse transformer-based text encoder. \\n \\nFuse embeddings using cross-attention layers. \\n \\nExpected Outcomes: \\n \\nImproved contextual understanding across modalities. \\n \\nEfficient representation learning for multi-modal tasks. \\n \\nFuture Work: \\n \\nExtend to video-text tasks. \\n \\nOptimize for real-time deployment.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5, 'source_file': 'proposal.pdf', 'file_type': 'pdf'}, page_content='Title: Proposal for a Multi-Modal Transformer Model \\n \\nProblem Statement: \\nCurrent models struggle to efficiently combine text and image features for contextual \\nunderstanding. \\n \\nObjective: \\nDevelop a lightweight transformer model integrating visual and textual embeddings. \\n \\nProposed Method: \\n \\nUse pre-trained visual encoder for image features. \\n \\nUse transformer-based text encoder. \\n \\nFuse embeddings using cross-attention layers. \\n \\nExpected Outcomes: \\n \\nImproved contextual understanding across modalities. \\n \\nEfficient representation learning for multi-modal tasks. \\n \\nFuture Work: \\n \\nExtend to video-text tasks. \\n \\nOptimize for real-time deployment.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6, 'source_file': 'proposal.pdf', 'file_type': 'pdf'}, page_content='Title: Proposal for a Multi-Modal Transformer Model \\n \\nProblem Statement: \\nCurrent models struggle to efficiently combine text and image features for contextual \\nunderstanding. \\n \\nObjective: \\nDevelop a lightweight transformer model integrating visual and textual embeddings. \\n \\nProposed Method: \\n \\nUse pre-trained visual encoder for image features. \\n \\nUse transformer-based text encoder. \\n \\nFuse embeddings using cross-attention layers. \\n \\nExpected Outcomes: \\n \\nImproved contextual understanding across modalities. \\n \\nEfficient representation learning for multi-modal tasks. \\n \\nFuture Work: \\n \\nExtend to video-text tasks. \\n \\nOptimize for real-time deployment.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7, 'source_file': 'proposal.pdf', 'file_type': 'pdf'}, page_content='Title: Proposal for a Multi-Modal Transformer Model \\n \\nProblem Statement: \\nCurrent models struggle to efficiently combine text and image features for contextual \\nunderstanding. \\n \\nObjective: \\nDevelop a lightweight transformer model integrating visual and textual embeddings. \\n \\nProposed Method: \\n \\nUse pre-trained visual encoder for image features. \\n \\nUse transformer-based text encoder. \\n \\nFuse embeddings using cross-attention layers. \\n \\nExpected Outcomes: \\n \\nImproved contextual understanding across modalities. \\n \\nEfficient representation learning for multi-modal tasks. \\n \\nFuture Work: \\n \\nExtend to video-text tasks. \\n \\nOptimize for real-time deployment.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 8, 'source_file': 'proposal.pdf', 'file_type': 'pdf'}, page_content='Title: Proposal for a Multi-Modal Transformer Model \\n \\nProblem Statement: \\nCurrent models struggle to efficiently combine text and image features for contextual \\nunderstanding. \\n \\nObjective: \\nDevelop a lightweight transformer model integrating visual and textual embeddings. \\n \\nProposed Method: \\n \\nUse pre-trained visual encoder for image features. \\n \\nUse transformer-based text encoder. \\n \\nFuse embeddings using cross-attention layers. \\n \\nExpected Outcomes: \\n \\nImproved contextual understanding across modalities. \\n \\nEfficient representation learning for multi-modal tasks. \\n \\nFuture Work: \\n \\nExtend to video-text tasks. \\n \\nOptimize for real-time deployment.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 9, 'source_file': 'proposal.pdf', 'file_type': 'pdf'}, page_content='Title: Proposal for a Multi-Modal Transformer Model \\n \\nProblem Statement: \\nCurrent models struggle to efficiently combine text and image features for contextual \\nunderstanding. \\n \\nObjective: \\nDevelop a lightweight transformer model integrating visual and textual embeddings. \\n \\nProposed Method: \\n \\nUse pre-trained visual encoder for image features. \\n \\nUse transformer-based text encoder. \\n \\nFuse embeddings using cross-attention layers. \\n \\nExpected Outcomes: \\n \\nImproved contextual understanding across modalities. \\n \\nEfficient representation learning for multi-modal tasks. \\n \\nFuture Work: \\n \\nExtend to video-text tasks. \\n \\nOptimize for real-time deployment.'),\n",
       " Document(metadata={'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 10, 'source_file': 'proposal.pdf', 'file_type': 'pdf'}, page_content='')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pdf_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "010b3c7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " split 48 into 52 chunks\n",
      "\n",
      "Example chunk\n",
      "content: Title: A Comparative Study of CNN-Based Object Detection Models \n",
      " \n",
      "Abstract: \n",
      "This research analyzes single-stage and two-stage object detection models using a benchmark \n",
      "image dataset. \n",
      " \n",
      "Introductio...\n",
      "content: {'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf'}\n"
     ]
    }
   ],
   "source": [
    "### Text splitting get into chunks\n",
    "\n",
    "def split_documents(documents, chunk_size=1000, chunk_overlap=200):\n",
    "    \"\"\"SPlit documents into chunks for better performance\"\"\"\n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size = chunk_size,\n",
    "        chunk_overlap = chunk_overlap,\n",
    "        length_function = len,\n",
    "        separators = [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "    )\n",
    "    split_docs= text_splitter.split_documents(documents)\n",
    "    print(f\" split {len(documents)} into {len(split_docs)} chunks\")\n",
    "    \n",
    "    if split_docs:\n",
    "        print(f\"\\nExample chunk\")\n",
    "        print((f\"content: {split_docs[0].page_content[:200]}...\"))\n",
    "        print((f\"content: {split_docs[0].metadata}\"))\n",
    "        \n",
    "    return split_docs\n",
    "        \n",
    "chunks= split_documents(all_pdf_documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0639020d",
   "metadata": {},
   "source": [
    "### Embedding and vector store in DB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "af4470f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/satyamshivam/Documents/projects/rag-agent-langchain/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List, Dict, Any, Tuple\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7a1d7a5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading weights: 100%|| 103/103 [00:00<00:00, 2319.87it/s, Materializing param=pooler.dense.weight]                             \n",
      "\u001b[1mBertModel LOAD REPORT\u001b[0m from: sentence-transformers/all-MiniLM-L6-v2\n",
      "Key                     | Status     |  | \n",
      "------------------------+------------+--+-\n",
      "embeddings.position_ids | UNEXPECTED |  | \n",
      "\n",
      "\u001b[3mNotes:\n",
      "- UNEXPECTED\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully. Embedding dimension: 384\n"
     ]
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"Handle document embedding generation\"\"\"\n",
    "    \n",
    "    def __init__(self, model_name:str =\"all-MiniLM-L6-v2\"):\n",
    "        \n",
    "        \"\"\"Initialize the embedding manager\n",
    "        \n",
    "        Args:\n",
    "            model_name: Hugging Face model name for sentence embedding\n",
    "        \"\"\"\n",
    "        \n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model() # going to load model _ for protected function\n",
    "        \n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the sentence transformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            \n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded successfully. Embedding dimension: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error:{e}\")\n",
    "            raise   \n",
    "        \n",
    "    def generate_embeddings(self, texts:List[str])->np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of text\"\"\"\n",
    "        \n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embedding for{len(texts)} texts...\")\n",
    "        embedding = self.model.encode(texts, show_progress_bar=True)\n",
    "        print(f\"Generated embeddings with shape: {embedding.shape}\")\n",
    "        return embedding\n",
    "    \n",
    "    def get_embedding_dimension(self):\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not found\")\n",
    "        \n",
    "        return self.model.get_sentence_embedding_dimension()\n",
    "    \n",
    "    \n",
    "### initialize the Embedding Manager\n",
    "\n",
    "embedding_manager = EmbeddingManager()\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180b29dd",
   "metadata": {},
   "source": [
    "### VectorStore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fb5af25d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collection: pdf_documents\n",
      "Existing document in collection: 52\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x30c43e900>"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore():\n",
    "    \n",
    "    def __init__(self, collection_name:str= 'pdf_documents', persistent_directory:str = '../data/vector_store'):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "        \n",
    "        Args:\n",
    "            collection name: Name of the chromaDB collection\n",
    "            persistent_directory: Directory to persist the vector store\n",
    "        \"\"\"\n",
    "        \n",
    "        self.collection_name = collection_name\n",
    "        self.persistent_directory = persistent_directory\n",
    "        self.client= None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "        \n",
    "    def _initialize_store(self):\n",
    "        \n",
    "        \"\"\"Initializing the chroma DB client and creating collection and persistent directory\"\"\"\n",
    "        try:\n",
    "            os.makedirs(self.persistent_directory, exist_ok=True)\n",
    "            \n",
    "            self.client = chromadb.PersistentClient(path= self.persistent_directory)\n",
    "            \n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name = self.collection_name,\n",
    "                metadata={\"description\":\"PDF docuemnt embeddings for RAG\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collection: {self.collection_name}\")\n",
    "            print(f\"Existing document in collection: {self.collection.count()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error while initializing Vector store. error: {e}\")\n",
    "            raise \n",
    "        \n",
    "    def add_document(self, documents: List[Any], embedding: np.ndarray):\n",
    "        \"\"\"Add documents and their embeddings to the vector store\n",
    "        \n",
    "        Args:\n",
    "            documents: List of langchain document\n",
    "            embeddings: Corresponding embeddings for the document\n",
    "\n",
    "        \"\"\"\n",
    "        \n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of document should match the number of embeddings\")\n",
    "        \n",
    "        print(f\"Adding {len(documents)} documents in the vector store\")\n",
    "        \n",
    "        # prepare the data for ChromaDB\n",
    "        \n",
    "        ids=[]\n",
    "        metadatas=[]\n",
    "        documents_text=[]\n",
    "        embeddings_list=[]\n",
    "        \n",
    "        for i, (doc, embedding) in enumerate(zip(documents, embeddings)):\n",
    "            # generate uuid for document\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "            print(f\"ids appending: {ids}\")\n",
    "            \n",
    "            # prepare metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index']=i\n",
    "            metadata['content_length']= len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "            \n",
    "            # document context \n",
    "            documents_text.append(doc.page_content)\n",
    "            \n",
    "            #embeddings\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "            \n",
    "            # try to add to the collection\n",
    "            try:\n",
    "                print(f\"Appending ids {ids}\")\n",
    "                print(f\"Appending met{metadata}\")\n",
    "                # print(f\"Appending {}\")\n",
    "                # print(f\"Appending {}\")\n",
    "                self.collection.add(\n",
    "                    ids=ids,\n",
    "                    metadatas=metadatas,\n",
    "                    embeddings = embeddings_list,\n",
    "                    documents = documents_text\n",
    "                )\n",
    "                \n",
    "                print(f\"Succesfully added {len(documents)} documents to the vector store\")\n",
    "                print(f\"Total number of document in collection: {self.collection.count()}\")\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Exception occured while adding document to vector store. Error: {e}\")\n",
    "                raise\n",
    "            \n",
    "    def get_count(self):\n",
    "        if not self.collection:\n",
    "            raise ValueError(\"No collection found\")\n",
    "        \n",
    "        return self.collection.count()\n",
    "            \n",
    "vector_store = VectorStore()\n",
    "vector_store            \n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5ab49717",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embedding for52 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|| 2/2 [00:00<00:00,  3.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (52, 384)\n",
      "Adding 52 documents in the vector store\n",
      "ids appending: ['doc_71ff0f19_0']\n",
      "Appending ids ['doc_71ff0f19_0']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 0, 'content_length': 981}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 53\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 1, 'content_length': 283}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 54\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 2, 'content_length': 169}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 55\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 3, 'content_length': 627}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 56\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 4, 'content_length': 627}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 57\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 5, 'content_length': 627}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 58\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 6, 'content_length': 627}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 59\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 7, 'content_length': 627}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 60\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 8, 'content_length': 627}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 61\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 8, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 9, 'content_length': 627}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 62\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 9, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 10, 'content_length': 627}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 63\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 10, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 11, 'content_length': 627}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 64\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 11, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 12, 'content_length': 627}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 65\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 12, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 13, 'content_length': 627}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 66\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 13, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 14, 'content_length': 627}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 67\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/objectdetection.pdf', 'file_path': '../data/pdf/objectdetection.pdf', 'total_pages': 15, 'format': 'PDF 1.4', 'title': 'objectdetection', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 14, 'source_file': 'objectdetection.pdf', 'file_type': 'pdf', 'doc_index': 15, 'content_length': 627}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 68\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'embeddings.pdf', 'file_type': 'pdf', 'doc_index': 16, 'content_length': 998}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 69\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'embeddings.pdf', 'file_type': 'pdf', 'doc_index': 17, 'content_length': 467}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 70\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1, 'source_file': 'embeddings.pdf', 'file_type': 'pdf', 'doc_index': 18, 'content_length': 223}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 71\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2, 'source_file': 'embeddings.pdf', 'file_type': 'pdf', 'doc_index': 19, 'content_length': 754}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 72\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3, 'source_file': 'embeddings.pdf', 'file_type': 'pdf', 'doc_index': 20, 'content_length': 754}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 73\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4, 'source_file': 'embeddings.pdf', 'file_type': 'pdf', 'doc_index': 21, 'content_length': 754}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 74\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5, 'source_file': 'embeddings.pdf', 'file_type': 'pdf', 'doc_index': 22, 'content_length': 754}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 75\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6, 'source_file': 'embeddings.pdf', 'file_type': 'pdf', 'doc_index': 23, 'content_length': 754}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 76\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7, 'source_file': 'embeddings.pdf', 'file_type': 'pdf', 'doc_index': 24, 'content_length': 998}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 77\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7, 'source_file': 'embeddings.pdf', 'file_type': 'pdf', 'doc_index': 25, 'content_length': 467}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 78\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 8, 'source_file': 'embeddings.pdf', 'file_type': 'pdf', 'doc_index': 26, 'content_length': 223}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 79\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 9, 'source_file': 'embeddings.pdf', 'file_type': 'pdf', 'doc_index': 27, 'content_length': 754}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 80\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/embeddings.pdf', 'file_path': '../data/pdf/embeddings.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'embeddings', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 10, 'source_file': 'embeddings.pdf', 'file_type': 'pdf', 'doc_index': 28, 'content_length': 754}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 81\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'attention.pdf', 'file_type': 'pdf', 'doc_index': 29, 'content_length': 970}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 82\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'attention.pdf', 'file_type': 'pdf', 'doc_index': 30, 'content_length': 720}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 83\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1, 'source_file': 'attention.pdf', 'file_type': 'pdf', 'doc_index': 31, 'content_length': 417}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 84\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2, 'source_file': 'attention.pdf', 'file_type': 'pdf', 'doc_index': 32, 'content_length': 970}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 85\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3, 'source_file': 'attention.pdf', 'file_type': 'pdf', 'doc_index': 33, 'content_length': 970}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 86\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4, 'source_file': 'attention.pdf', 'file_type': 'pdf', 'doc_index': 34, 'content_length': 970}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 87\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5, 'source_file': 'attention.pdf', 'file_type': 'pdf', 'doc_index': 35, 'content_length': 970}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 88\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6, 'source_file': 'attention.pdf', 'file_type': 'pdf', 'doc_index': 36, 'content_length': 970}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 89\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7, 'source_file': 'attention.pdf', 'file_type': 'pdf', 'doc_index': 37, 'content_length': 970}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 90\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 8, 'source_file': 'attention.pdf', 'file_type': 'pdf', 'doc_index': 38, 'content_length': 970}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 91\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 9, 'source_file': 'attention.pdf', 'file_type': 'pdf', 'doc_index': 39, 'content_length': 970}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 92\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/attention.pdf', 'file_path': '../data/pdf/attention.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'attention.pdf', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 10, 'source_file': 'attention.pdf', 'file_type': 'pdf', 'doc_index': 40, 'content_length': 970}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 93\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'proposal.pdf', 'file_type': 'pdf', 'doc_index': 41, 'content_length': 957}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 94\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 0, 'source_file': 'proposal.pdf', 'file_type': 'pdf', 'doc_index': 42, 'content_length': 225}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 95\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 1, 'source_file': 'proposal.pdf', 'file_type': 'pdf', 'doc_index': 43, 'content_length': 268}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 96\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 2, 'source_file': 'proposal.pdf', 'file_type': 'pdf', 'doc_index': 44, 'content_length': 659}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 97\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44', 'doc_afca3c19_45']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44', 'doc_afca3c19_45']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 3, 'source_file': 'proposal.pdf', 'file_type': 'pdf', 'doc_index': 45, 'content_length': 659}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 98\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44', 'doc_afca3c19_45', 'doc_d7bf1102_46']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44', 'doc_afca3c19_45', 'doc_d7bf1102_46']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 4, 'source_file': 'proposal.pdf', 'file_type': 'pdf', 'doc_index': 46, 'content_length': 659}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 99\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44', 'doc_afca3c19_45', 'doc_d7bf1102_46', 'doc_9fb176dc_47']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44', 'doc_afca3c19_45', 'doc_d7bf1102_46', 'doc_9fb176dc_47']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 5, 'source_file': 'proposal.pdf', 'file_type': 'pdf', 'doc_index': 47, 'content_length': 659}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 100\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44', 'doc_afca3c19_45', 'doc_d7bf1102_46', 'doc_9fb176dc_47', 'doc_52afee22_48']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44', 'doc_afca3c19_45', 'doc_d7bf1102_46', 'doc_9fb176dc_47', 'doc_52afee22_48']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 6, 'source_file': 'proposal.pdf', 'file_type': 'pdf', 'doc_index': 48, 'content_length': 659}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 101\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44', 'doc_afca3c19_45', 'doc_d7bf1102_46', 'doc_9fb176dc_47', 'doc_52afee22_48', 'doc_c665a96f_49']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44', 'doc_afca3c19_45', 'doc_d7bf1102_46', 'doc_9fb176dc_47', 'doc_52afee22_48', 'doc_c665a96f_49']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 7, 'source_file': 'proposal.pdf', 'file_type': 'pdf', 'doc_index': 49, 'content_length': 659}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 102\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44', 'doc_afca3c19_45', 'doc_d7bf1102_46', 'doc_9fb176dc_47', 'doc_52afee22_48', 'doc_c665a96f_49', 'doc_97a26504_50']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44', 'doc_afca3c19_45', 'doc_d7bf1102_46', 'doc_9fb176dc_47', 'doc_52afee22_48', 'doc_c665a96f_49', 'doc_97a26504_50']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 8, 'source_file': 'proposal.pdf', 'file_type': 'pdf', 'doc_index': 50, 'content_length': 659}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 103\n",
      "ids appending: ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44', 'doc_afca3c19_45', 'doc_d7bf1102_46', 'doc_9fb176dc_47', 'doc_52afee22_48', 'doc_c665a96f_49', 'doc_97a26504_50', 'doc_cf964836_51']\n",
      "Appending ids ['doc_71ff0f19_0', 'doc_16a6c748_1', 'doc_bd15d9d8_2', 'doc_f84f6305_3', 'doc_48dcdfab_4', 'doc_2f1f1f79_5', 'doc_c5390030_6', 'doc_788feaee_7', 'doc_718fa8d9_8', 'doc_75e4b9e9_9', 'doc_322c18ca_10', 'doc_7489d93f_11', 'doc_63ac01ca_12', 'doc_c13ec9e9_13', 'doc_70c89872_14', 'doc_574f0114_15', 'doc_c17f7f8f_16', 'doc_df69e425_17', 'doc_945203de_18', 'doc_35c29ec4_19', 'doc_c14a35e5_20', 'doc_2eb76ce6_21', 'doc_3e19c584_22', 'doc_2eb50c8c_23', 'doc_b05375ea_24', 'doc_bc0bdafd_25', 'doc_462f0f5d_26', 'doc_9253fddb_27', 'doc_2e28dfc9_28', 'doc_d8055b1a_29', 'doc_fd1d647e_30', 'doc_c99c5f46_31', 'doc_e5a8a411_32', 'doc_ea8e86ca_33', 'doc_9efd10a3_34', 'doc_17430423_35', 'doc_54772e6f_36', 'doc_bac6cd90_37', 'doc_02eaeb3a_38', 'doc_9b519c4b_39', 'doc_08819287_40', 'doc_9e6f2f2d_41', 'doc_7aa659a1_42', 'doc_cd80f37e_43', 'doc_1080afda_44', 'doc_afca3c19_45', 'doc_d7bf1102_46', 'doc_9fb176dc_47', 'doc_52afee22_48', 'doc_c665a96f_49', 'doc_97a26504_50', 'doc_cf964836_51']\n",
      "Appending met{'producer': 'Skia/PDF m147 Google Docs Renderer', 'creator': '', 'creationdate': '', 'source': '../data/pdf/proposal.pdf', 'file_path': '../data/pdf/proposal.pdf', 'total_pages': 11, 'format': 'PDF 1.4', 'title': 'proposal', 'author': '', 'subject': '', 'keywords': '', 'moddate': '', 'trapped': '', 'modDate': '', 'creationDate': '', 'page': 9, 'source_file': 'proposal.pdf', 'file_type': 'pdf', 'doc_index': 51, 'content_length': 659}\n",
      "Succesfully added 52 documents to the vector store\n",
      "Total number of document in collection: 104\n"
     ]
    }
   ],
   "source": [
    "### adding chunks to the vector store\n",
    "# convert the text into embeddings\n",
    "\n",
    "texts = [doc.page_content for doc in chunks]\n",
    "\n",
    "#generate the embedding\n",
    "embeddings = embedding_manager.generate_embeddings(texts)\n",
    "\n",
    "vector_store.add_document(chunks, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2808eca9",
   "metadata": {},
   "source": [
    "### Retreival pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7bf6c681",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RagRetreiver:\n",
    "    \"\"\"Handles Query based retreival from the vector store\"\"\"\n",
    "    \n",
    "    def __init__(self, embedding_manager: EmbeddingManager, vector_store: VectorStore):\n",
    "        \"\"\"\n",
    "        Initialize the retreiver\n",
    "        \n",
    "        Args:\n",
    "            vector_store: Vector store containing document embeddings\n",
    "            embedding_manager: Manager for generating the embeddings\n",
    "        \"\"\"\n",
    "        \n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "        \n",
    "    def retreive(self, query:str, top_k: int =5, score_thresold: float = 0.0)-> List[Dict[str,Any]]:\n",
    "        \"\"\"\n",
    "        Retreive relevant document for the given query\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Nop of top results to return\n",
    "            score_thresold: Minimum similarity score thresold\n",
    "            \n",
    "        Returns:\n",
    "            List of dictionaries containing retreived documents and metadata\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"Retreiving documents for query {query}\")\n",
    "        #generating the embeddings for query\n",
    "        \n",
    "        query_embedding = embedding_manager.generate_embeddings([query])[0]\n",
    "        \n",
    "        #Search in vector store\n",
    "        try:\n",
    "            results= self.vector_store.collection.query(\n",
    "                query_embeddings= [query_embedding.tolist()],\n",
    "                n_results= top_k\n",
    "            )\n",
    "            \n",
    "            # process the results\n",
    "            retreived_docs = []\n",
    "            \n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents= results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "                ids= results['ids'][0]\n",
    "                \n",
    "                for i, (doc_id, document, metadata, distance) in enumerate(zip(ids, documents, metadatas, distances)):\n",
    "                    # convert the similarity score (chormaDB uses cosine distance)\n",
    "                    similarity_score =1-distance\n",
    "                    \n",
    "                    if similarity_score >= score_thresold:\n",
    "                        retreived_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content': document,\n",
    "                            'metadata': metadata,\n",
    "                            'similarity_score': similarity_score,\n",
    "                            'distance': distance,\n",
    "                            'rank': i+1\n",
    "                        })\n",
    "                        \n",
    "                        print(f\"Retreived {len(retreived_docs)} document after filtering based on thresold\")\n",
    "                else:\n",
    "                    print(\"No documents found\")\n",
    "                        \n",
    "                return retreived_docs\n",
    "        except Exception as e:\n",
    "            print(f\"error while retreiving {e}\")\n",
    "            raise\n",
    "            \n",
    "rag_retreiver = RagRetreiver(embedding_manager, vector_store)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "976f70ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retreiving documents for query Faster R-CNN produced higher accuracy\n",
      "Generating embedding for1 texts...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|| 1/1 [00:00<00:00,  1.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated embeddings with shape: (1, 384)\n",
      "Retreived 1 document after filtering based on thresold\n",
      "Retreived 2 document after filtering based on thresold\n",
      "No documents found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_f41d5fec_2',\n",
       "  'content': 'YOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.',\n",
       "  'metadata': {'modDate': '',\n",
       "   'author': '',\n",
       "   'source': '../data/pdf/objectdetection.pdf',\n",
       "   'moddate': '',\n",
       "   'producer': 'Skia/PDF m147 Google Docs Renderer',\n",
       "   'file_path': '../data/pdf/objectdetection.pdf',\n",
       "   'creationDate': '',\n",
       "   'source_file': 'objectdetection.pdf',\n",
       "   'title': 'objectdetection',\n",
       "   'trapped': '',\n",
       "   'subject': '',\n",
       "   'keywords': '',\n",
       "   'creator': '',\n",
       "   'doc_index': 2,\n",
       "   'file_type': 'pdf',\n",
       "   'total_pages': 15,\n",
       "   'content_length': 169,\n",
       "   'format': 'PDF 1.4',\n",
       "   'page': 1,\n",
       "   'creationdate': ''},\n",
       "  'similarity_score': 0.35669124126434326,\n",
       "  'distance': 0.6433087587356567,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_bd15d9d8_2',\n",
       "  'content': 'YOLO achieved faster inference. \\n \\nFaster R-CNN produced higher accuracy. \\n \\nConclusion: \\nModel selection depends on application requirements between speed and accuracy.',\n",
       "  'metadata': {'source': '../data/pdf/objectdetection.pdf',\n",
       "   'keywords': '',\n",
       "   'subject': '',\n",
       "   'doc_index': 2,\n",
       "   'page': 1,\n",
       "   'trapped': '',\n",
       "   'total_pages': 15,\n",
       "   'format': 'PDF 1.4',\n",
       "   'author': '',\n",
       "   'content_length': 169,\n",
       "   'creator': '',\n",
       "   'source_file': 'objectdetection.pdf',\n",
       "   'creationDate': '',\n",
       "   'file_type': 'pdf',\n",
       "   'file_path': '../data/pdf/objectdetection.pdf',\n",
       "   'title': 'objectdetection',\n",
       "   'modDate': '',\n",
       "   'creationdate': '',\n",
       "   'producer': 'Skia/PDF m147 Google Docs Renderer',\n",
       "   'moddate': ''},\n",
       "  'similarity_score': 0.35669124126434326,\n",
       "  'distance': 0.6433087587356567,\n",
       "  'rank': 2}]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_retreiver.retreive('Faster R-CNN produced higher accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874f3ea2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-agent-langchain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
